{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-25T04:20:55.856437Z",
     "iopub.status.busy": "2025-03-25T04:20:55.856097Z",
     "iopub.status.idle": "2025-03-25T04:20:56.249810Z",
     "shell.execute_reply": "2025-03-25T04:20:56.248719Z",
     "shell.execute_reply.started": "2025-03-25T04:20:55.856407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/maferdata/poem_wordsworth.txt\n",
      "/kaggle/input/maferdata/example1.txt\n",
      "/kaggle/input/maferdata/airline_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EJERCICIO 2 - Python Text Analysis: Preprocessing üë©üèª‚Äçüíªüìâüìà**\n",
    "\n",
    "**GRUPO 9:**\n",
    "* Jonathan Diego √Ålvarez\n",
    "* Juan Carlos Arias\n",
    "* Mar√≠a Fernanda Pacheco\n",
    "* Jairo Joel Siza\n",
    "\n",
    "**Objetivos de aprendizaje**\n",
    "\n",
    "1. Aprender los pasos m√°s frecuentes para el preprocesamiento de datos de texto, as√≠ como las operaciones espec√≠ficas para el preprocesamiento de datos de Twitter.\n",
    "2. Conocer los paquetes de NLP m√°s utilizados y sus capacidades.\n",
    "3. Comprender los tokenizadores y c√≥mo han cambiado desde la llegada de los Modelos de Lenguaje de Gran tama√±o.\n",
    "\n",
    "**Iconos utilizados en este Notebook**\n",
    "\n",
    "üîîPregunta: Una pregunta r√°pida para ayudar a entender qu√© est√° pasando.\n",
    "\n",
    "ü•äDesaf√≠o: Ejercicios interactivos. ¬°Ser√°n trabajados en el taller!\n",
    "\n",
    "‚ö†Ô∏èAdvertencia: Aviso sobre cuestiones complicadas o errores comunes.\n",
    "\n",
    "üé¨Demo: Demostraci√≥n de algo m√°s avanzado: ¬°As√≠ sabr√°s para qu√© se puede usar Python! \n",
    "\n",
    "**Secciones**\n",
    "\n",
    "1. Preprocesamiento\n",
    "\n",
    "En esta serie de talleres seccionados en tres partes, aprenderemos los fundamentos para realizar An√°lisis de Texto en Python. Estas t√©cnicas se enmarcan en el √°mbito del Procesamiento del Lenguaje Natural o *Natural Language Processing* (NLP). El NLP es un campo que se ocupa de la identificaci√≥n y extracci√≥n de patrones del lenguaje, principalmente en textos escritos.\n",
    "A lo largo de la serie de talleres, interactuaremos con diversos paquetes para realizar an√°lisis de texto: empezando desde m√©todos de cadenas simples hasta paquetes de NLP espec√≠ficos, como nltk, spaCy, y los Modelos de Lenguaje de Gran tama√±o o Large Language Models (LLM) m√°s recientes (BERT).\n",
    "\n",
    "Ahora, instalemos correctamente estos paquetes antes de profundizar en el material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:20:56.251599Z",
     "iopub.status.busy": "2025-03-25T04:20:56.251174Z",
     "iopub.status.idle": "2025-03-25T04:21:18.293063Z",
     "shell.execute_reply": "2025-03-25T04:21:18.291709Z",
     "shell.execute_reply.started": "2025-03-25T04:20:56.251572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: NLTK in /usr/local/lib/python3.10/dist-packages (3.2.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from NLTK) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spaCy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.11.0a2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spaCy) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (2.29.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2025.1.31)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spaCy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spaCy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spaCy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spaCy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spaCy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spaCy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spaCy) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spaCy) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spaCy) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spaCy) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spaCy) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spaCy) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.0a2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.29.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "#Descomente las siguientes l√≠neas para instalar paquetes/modelos\n",
    "%pip install NLTK\n",
    "%pip install transformers\n",
    "%pip install spaCy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento\n",
    "\n",
    "En la Parte #1 de este taller conoceremos el primer paso del an√°lisis de texto. Nuestro objetivo es convertir los datos de texto puros y desordenados (sin procesar) a un formato consistente. A este proceso a menudo se le denomina preprocesamiento, limpieza de texto o normalizaci√≥n de texto.\n",
    "\n",
    "Te dar√°s cuenta que al final del preprocesamiento nuestros datos todav√≠a est√°n en un formato que podemos leer y comprender.\n",
    "\n",
    "En las Partes #2 y #3, comenzaremos nuestra incursi√≥n en la conversi√≥n de datos de texto en una *representaci√≥n num√©rica* (un formato que las computadoras pueden manejar m√°s f√°cilmente).\n",
    "\n",
    "üîîPregunta: Hagamos una pausa por un minuto para reflexionar sobre nuestras experiencias previas trabajando con datos de texto.\n",
    "* ¬øCu√°l es el formato de los datos de texto con los que has interactuado (texto plano, CSV o XML)?\n",
    "* ¬øDe d√≥nde provienen (corpus estructurado, datos extra√≠dos de la web, datos de encuestas)?\n",
    "* ¬øEst√°n desordenados (es decir, los datos est√°n formateados de manera consistente)?\n",
    "\n",
    "# Procesos comunes\n",
    "\n",
    "El preprocesamiento no es algo que podemos lograr con una sola l√≠nea de c√≥digo. A menudo, empezamos familiariz√°ndonos con los datos y, a lo largo del camino, obtenemos una comprensi√≥n m√°s clara de la granularidad del preprocesamiento que queremos aplicar.\n",
    "\n",
    "Normalmente, comenzamos aplicando un conjunto de procesos com√∫nmente usados para limpiar los datos. Estas operaciones no alteran sustancialmente la forma ni el significado de los datos; sirven como un procedimiento estandarizado para reorganizar los datos en un formato consistente.\n",
    "\n",
    "Los siguientes procesos, por ejemplo, son com√∫nmente aplicados para preprocesar textos en ingl√©s de diversos g√©neros. Estas operaciones se pueden realizar utilizando funciones integradas de Python como: m√©todos de cadena y expresiones regulares.\n",
    "\n",
    "* Poner el texto en min√∫sculas\n",
    "* Eliminar signos de puntuaci√≥n\n",
    "* Eliminar espacios en blanco adicionales\n",
    "* Eliminar palabras vac√≠as\n",
    "\n",
    "Despu√©s del procesamiento inicial, podemos optar por realizar procesos espec√≠ficos para la tarea, cuyos detalles a menudo dependen de la tarea posterior que queremos realizar y de la naturaleza de los datos textuales (es decir, sus caracter√≠sticas estil√≠sticas y ling√º√≠sticas).\n",
    "\n",
    "¬°Antes de profundizar en estas operaciones, echemos un vistazo a nuestros datos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar los datos de texto\n",
    "\n",
    "Los datos de texto con los que trabajaremos est√°n en un archivo CSV. Estos datos contienen tweets sobre aerol√≠neas Estadounidenses, extra√≠dos de febrero del 2015.\n",
    "\n",
    "Leamos el archivo *airline_tweets.csv* dentro del dataframe con la biblioteca *pandas*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.295160Z",
     "iopub.status.busy": "2025-03-25T04:21:18.294811Z",
     "iopub.status.idle": "2025-03-25T04:21:18.393144Z",
     "shell.execute_reply": "2025-03-25T04:21:18.391815Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.295120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importa pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Ruta del archivo que contiene los datos\n",
    "csv_path = '/kaggle/input/maferdata/airline_tweets.csv'\n",
    "\n",
    "#Especifica el separador\n",
    "tweets = pd.read_csv(csv_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.394772Z",
     "iopub.status.busy": "2025-03-25T04:21:18.394460Z",
     "iopub.status.idle": "2025-03-25T04:21:18.418441Z",
     "shell.execute_reply": "2025-03-25T04:21:18.417253Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.394744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Muestra las primeras cinco filas\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataframe tiene una fila por tweet. El texto del tweet se muestra en la columna ***texto***.\n",
    "\n",
    "* text (str): el texto del tweet.\n",
    "\n",
    "Otros metadatos que nos interesan incluyen:\n",
    "\n",
    "* airline_sentiment (str): el sentimiento del tweet etiquetado como \"neutral\", \"positivo\", o \"negativo\".\n",
    "* airline (str): la aerol√≠nea sobre la que se tuitea.\n",
    "* retweet count (int): cu√°ntas veces se retuite√≥ el tweet.\n",
    "\n",
    "Echemos un vistazo a algunos de los tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.419840Z",
     "iopub.status.busy": "2025-03-25T04:21:18.419556Z",
     "iopub.status.idle": "2025-03-25T04:21:18.426086Z",
     "shell.execute_reply": "2025-03-25T04:21:18.425017Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.419816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica What @dhepburn said.\n",
      "@VirginAmerica plus you've added commercials to the experience... tacky.\n",
      "@VirginAmerica I didn't today... Must mean I need to take another trip!\n"
     ]
    }
   ],
   "source": [
    "print(tweets['text'].iloc[0])\n",
    "print(tweets['text'].iloc[1])\n",
    "print(tweets['text'].iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîîPregunta: ¬øQu√© has notado? ¬øCu√°les son las caracter√≠sticas estil√≠sticas de los tweets?\n",
    "\n",
    "# Lowercasing / Min√∫sculas\n",
    "\n",
    "Si bien reconocemos que el uso de may√∫sculas y min√∫sculas de una palabra es informativo, a menudo no trabajamos en contextos donde podamos utilizar adecuadamente esta informaci√≥n.\n",
    "\n",
    "Con mayor frecuencia, el an√°lisis posterior que realizamos no distingue entre may√∫sculas y min√∫sculas. Por ejemplo, en el an√°lisis de frecuencia, queremos tener en cuenta las diversas formas de una misma palabra. Poner los datos de texto en min√∫sculas ayuda en este proceso y simplifica nuestro an√°lisis.\n",
    "\n",
    "Podemos lograr f√°cilmente la conversi√≥n a min√∫sculas con el m√©todo de cadena ***.lower()***; consulta la documentaci√≥n para obtener funciones m√°s √∫tiles.\n",
    "\n",
    "Apliqu√©moslo al siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.427462Z",
     "iopub.status.busy": "2025-03-25T04:21:18.427181Z",
     "iopub.status.idle": "2025-03-25T04:21:18.444325Z",
     "shell.execute_reply": "2025-03-25T04:21:18.443357Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.427437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica I was scheduled for SFO 2 DAL flight 714 today. Changed to 24th due weather. Looks like flight still on?\n"
     ]
    }
   ],
   "source": [
    "#Imprime el primer ejemplo.\n",
    "first_example = tweets['text'][108]\n",
    "print(first_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.445785Z",
     "iopub.status.busy": "2025-03-25T04:21:18.445472Z",
     "iopub.status.idle": "2025-03-25T04:21:18.465080Z",
     "shell.execute_reply": "2025-03-25T04:21:18.463937Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.445759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "==================================================\n",
      "@virginamerica i was scheduled for sfo 2 dal flight 714 today. changed to 24th due weather. looks like flight still on?\n",
      "==================================================\n",
      "@VIRGINAMERICA I WAS SCHEDULED FOR SFO 2 DAL FLIGHT 714 TODAY. CHANGED TO 24TH DUE WEATHER. LOOKS LIKE FLIGHT STILL ON?\n"
     ]
    }
   ],
   "source": [
    "#Comprueba si todos los caracteres est√°n en min√∫sculas\n",
    "print(first_example.islower())\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "#Convierte a min√∫sculas\n",
    "print(first_example.lower())\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "#Convierte a may√∫sculas\n",
    "print(first_example.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar caracteres de espacio en blanco adicionales #\n",
    "\n",
    "A veces podemos encontrarnos con textos que contienen extra√±os espacios en blanco, como por ejemplo: espacios, tabulaciones y caracteres de nueva l√≠nea, lo cual es particularmente com√∫n cuando el texto se extrae de p√°ginas web. Antes de profundizar en los detalles, presentemos brevemente las Expresiones Regulares **(regex)** y el paquete **re**.\n",
    "\n",
    "Las expresiones regulares son una forma poderosa de buscar patrones de cadenas espec√≠ficos en grandes corpus. Tienen una curva de aprendizaje infamemente pronunciada, pero pueden ser muy eficientes cuando los dominamos. Muchos paquetes de NLP dependen en gran medida de expresiones regulares. Los testers de expresiones regulares, como **regex101**, son herramientas √∫tiles tanto para comprender como para crear expresiones regulares.\n",
    "\n",
    "Nuestro objetivo en este taller no es profundizar en las expresiones regulares, ni siquiera verlas superficialmente; por el contrario, queremos expon√©rtelos para que est√©s mejor preparado para realizar un an√°lisis en profundidad en el futuro.\n",
    "\n",
    "El siguiente ejemplo es un poema de William Wordsworth. Como muchos poemas, el texto puede contener saltos de l√≠nea adicionales (es decir, caracteres de nueva l√≠nea, **\\n**) que queremos eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.467944Z",
     "iopub.status.busy": "2025-03-25T04:21:18.467566Z",
     "iopub.status.idle": "2025-03-25T04:21:18.481782Z",
     "shell.execute_reply": "2025-03-25T04:21:18.480642Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.467902Z"
    }
   },
   "outputs": [],
   "source": [
    "#Ruta del archivo que contiene el poema\n",
    "text_path = '/kaggle/input/maferdata/poem_wordsworth.txt'\n",
    "\n",
    "#Lee el poema en\n",
    "with open(text_path, 'r') as file:\n",
    "    text = file.read()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, el formato del poema es como una cadena continua de texto con saltos de l√≠nea al final de cada l√≠nea, lo que dificulta su lectura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.484305Z",
     "iopub.status.busy": "2025-03-25T04:21:18.483912Z",
     "iopub.status.idle": "2025-03-25T04:21:18.494422Z",
     "shell.execute_reply": "2025-03-25T04:21:18.493348Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.484269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I wandered lonely as a cloud\\n\\n\\nI wandered lonely as a cloud\\nThat floats on high o'er vales and hills,\\nWhen all at once I saw a crowd,\\nA host, of golden daffodils;\\nBeside the lake, beneath the trees,\\nFluttering and dancing in the breeze.\\n\\nContinuous as the stars that shine\\nAnd twinkle on the milky way,\\nThey stretched in never-ending line\\nAlong the margin of a bay:\\nTen thousand saw I at a glance,\\nTossing their heads in sprightly dance.\\n\\nThe waves beside them danced; but they\\nOut-did the sparkling waves in glee:\\nA poet could not but be gay,\\nIn such a jocund company:\\nI gazed‚Äîand gazed‚Äîbut little thought\\nWhat wealth the show to me had brought:\\n\\nFor oft, when on my couch I lie\\nIn vacant or in pensive mood,\\nThey flash upon that inward eye\\nWhich is the bliss of solitude;\\nAnd then my heart with pleasure fills,\\nAnd dances with the daffodils.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una funci√≥n √∫til que podemos usar para mostrar el poema correctamente es ***.splitlines()***. Como su nombre lo indica, divide una secuencia larga de texto en una lista de l√≠neas, siempre que haya un car√°cter de nueva l√≠nea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.495609Z",
     "iopub.status.busy": "2025-03-25T04:21:18.495354Z",
     "iopub.status.idle": "2025-03-25T04:21:18.513549Z",
     "shell.execute_reply": "2025-03-25T04:21:18.512274Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.495587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I wandered lonely as a cloud',\n",
       " '',\n",
       " '',\n",
       " 'I wandered lonely as a cloud',\n",
       " \"That floats on high o'er vales and hills,\",\n",
       " 'When all at once I saw a crowd,',\n",
       " 'A host, of golden daffodils;',\n",
       " 'Beside the lake, beneath the trees,',\n",
       " 'Fluttering and dancing in the breeze.',\n",
       " '',\n",
       " 'Continuous as the stars that shine',\n",
       " 'And twinkle on the milky way,',\n",
       " 'They stretched in never-ending line',\n",
       " 'Along the margin of a bay:',\n",
       " 'Ten thousand saw I at a glance,',\n",
       " 'Tossing their heads in sprightly dance.',\n",
       " '',\n",
       " 'The waves beside them danced; but they',\n",
       " 'Out-did the sparkling waves in glee:',\n",
       " 'A poet could not but be gay,',\n",
       " 'In such a jocund company:',\n",
       " 'I gazed‚Äîand gazed‚Äîbut little thought',\n",
       " 'What wealth the show to me had brought:',\n",
       " '',\n",
       " 'For oft, when on my couch I lie',\n",
       " 'In vacant or in pensive mood,',\n",
       " 'They flash upon that inward eye',\n",
       " 'Which is the bliss of solitude;',\n",
       " 'And then my heart with pleasure fills,',\n",
       " 'And dances with the daffodils.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Divide la cadena √∫nica en una lista de l√≠neas\n",
    "text.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvamos a nuestros datos de tweets para ver un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.514912Z",
     "iopub.status.busy": "2025-03-25T04:21:18.514462Z",
     "iopub.status.idle": "2025-03-25T04:21:18.534188Z",
     "shell.execute_reply": "2025-03-25T04:21:18.533067Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.514851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imprime el segundo ejemplo\n",
    "second_example = tweets['text'][5]\n",
    "second_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, no queremos dividir el tweet en una lista de cadenas. Todav√≠a esperamos una sola cadena de texto, pero nos gustar√≠a eliminar completamente el salto de l√≠nea de la cadena.\n",
    "\n",
    "El m√©todo de cadena ***.strip()*** realiza efectivamente el trabajo de quitar los espacios en ambos extremos del texto. Sin embargo, no funcionar√° en nuestro ejemplo, ya que el car√°cter de nueva l√≠nea est√° en medio de la cadena.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.535826Z",
     "iopub.status.busy": "2025-03-25T04:21:18.535489Z",
     "iopub.status.idle": "2025-03-25T04:21:18.551405Z",
     "shell.execute_reply": "2025-03-25T04:21:18.550368Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.535799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.Strip() solo elimin√≥ los espacios en blanco en ambos extremos\n",
    "second_example.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu√≠ es donde las expresiones regulares pueden ser realmente √∫tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.552941Z",
     "iopub.status.busy": "2025-03-25T04:21:18.552530Z",
     "iopub.status.idle": "2025-03-25T04:21:18.566944Z",
     "shell.execute_reply": "2025-03-25T04:21:18.565802Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.552902Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, con expresiones regulares, esencialmente las estamos utilizando para hacer coincidir un patr√≥n que hemos identificado en los datos de texto, y queremos realizar algunas operaciones sobre la parte coincidente: extraerla, reemplazarla por algo m√°s o eliminarla completamente. Por lo tanto, la forma en que funciona **regex** se puede desglosar en los siguientes pasos:\n",
    "\n",
    "* Identificar y escribir el patr√≥n en expresi√≥n regular Identificar y escribir el patr√≥n en expresi√≥n regular  (r'PATTERN')\n",
    "* Escribir el reemplazo para el patr√≥n ('REPLACEMENT')\n",
    "* Llamar a la funci√≥n regex espec√≠fica (por ejemplo: **re.sub()**)\n",
    "\n",
    "En nuestro ejemplo, el patr√≥n que buscamos es ***\\s***, que es la expresi√≥n regular abreviada para cualquier espacio en blanco (inclu√≠dos ***\\n*** y ***\\t***). Tambi√©n a√±adimos un cuantificador **+** al final: ***\\s+***. Esto significa que queremos capturar una o m√°s ocurrencias del car√°cter espacio en blanco. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.568324Z",
     "iopub.status.busy": "2025-03-25T04:21:18.567985Z",
     "iopub.status.idle": "2025-03-25T04:21:18.583186Z",
     "shell.execute_reply": "2025-03-25T04:21:18.581973Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.568297Z"
    }
   },
   "outputs": [],
   "source": [
    "#Escribe un patr√≥n en expresiones regulares\n",
    "blankspace_pattern = r'\\s+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El reemplazo de uno o m√°s espacios en blanco es exactamente un solo espacio, que es el l√≠mite can√≥nico de una palabra en ingl√©s. Cualquier espacio adicional se reducir√° a un solo espacio en blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.584427Z",
     "iopub.status.busy": "2025-03-25T04:21:18.584142Z",
     "iopub.status.idle": "2025-03-25T04:21:18.600204Z",
     "shell.execute_reply": "2025-03-25T04:21:18.598999Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.584400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Escribe un reemplazo para el patr√≥n identificado.\n",
    "blankspace_repl = ' '\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, combinamos todo usando la funci√≥n ***re.sub()***, lo que significa que queremos sustituir un patr√≥n por un reemplazo. La funci√≥n acepta tres argumentos: el patr√≥n, el reemplazo y la cadena a la que queremos aplicar la funci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.601452Z",
     "iopub.status.busy": "2025-03-25T04:21:18.601151Z",
     "iopub.status.idle": "2025-03-25T04:21:18.611629Z",
     "shell.execute_reply": "2025-03-25T04:21:18.610742Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.601411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing. it's really the only bad thing about flying VA\n"
     ]
    }
   ],
   "source": [
    "#Reemplace los espacios en blanco con ' '\n",
    "clean_text = re.sub(pattern = blankspace_pattern, \n",
    "                    repl = blankspace_repl, \n",
    "                    string = second_example)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°Ta-da! El car√°cter de nueva l√≠nea ya no est√°."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar signos de puntuaci√≥n #\n",
    "\n",
    "A veces solo nos interesa analizar caracteres alfanum√©ricos (es decir, letras y n√∫meros), en cuyo caso podr√≠amos querer eliminar los signos de puntuaci√≥n.\n",
    "\n",
    "El m√≥dulo ***string*** contiene una lista de signos de puntuaci√≥n predefinidos. ¬°Vamos a imprimirlos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.613111Z",
     "iopub.status.busy": "2025-03-25T04:21:18.612718Z",
     "iopub.status.idle": "2025-03-25T04:21:18.629826Z",
     "shell.execute_reply": "2025-03-25T04:21:18.628795Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.613073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Carga una lista predefinida de signos de puntuaci√≥n\n",
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la pr√°ctica, para eliminar estos caracteres de puntuaci√≥n, podemos simplemente iterar sobre el texto y eliminar los caracteres que se encuentran en la lista, como se muestra a continuaci√≥n en la funci√≥n **remove_punct**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.631195Z",
     "iopub.status.busy": "2025-03-25T04:21:18.630894Z",
     "iopub.status.idle": "2025-03-25T04:21:18.647007Z",
     "shell.execute_reply": "2025-03-25T04:21:18.645973Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.631161Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    '''Eliminar signos de puntuaci√≥n en el texto de entrada'''\n",
    "    \n",
    "    #Selecciona caracteres que no est√©n en puntuaci√≥n\n",
    "    no_punct = []\n",
    "    for char in text:\n",
    "        if char not in punctuation:\n",
    "            no_punct.append(char)\n",
    "\n",
    "    #Une los caracteres en una cadena\n",
    "    text_no_punct = ''.join(no_punct)   \n",
    "    \n",
    "    return text_no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquemos la funci√≥n al ejemplo siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.648243Z",
     "iopub.status.busy": "2025-03-25T04:21:18.647956Z",
     "iopub.status.idle": "2025-03-25T04:21:18.666514Z",
     "shell.execute_reply": "2025-03-25T04:21:18.665663Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.648218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica why are your first fares in May over three times more than other carriers when all seats are available to select???\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'VirginAmerica why are your first fares in May over three times more than other carriers when all seats are available to select'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imprime el tercer ejemplo\n",
    "third_example = tweets['text'][20]\n",
    "print(third_example)\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "# Aplica la funci√≥n\n",
    "remove_punct(third_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a intentarlo con otro tweet. ¬øQu√© has notado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.667876Z",
     "iopub.status.busy": "2025-03-25T04:21:18.667592Z",
     "iopub.status.idle": "2025-03-25T04:21:18.685497Z",
     "shell.execute_reply": "2025-03-25T04:21:18.684598Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.667835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica trying to add my boy Prince to my ressie. SF this Thursday @VirginAmerica from LAX http://t.co/GsB2J3c4gM\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'VirginAmerica trying to add my boy Prince to my ressie SF this Thursday VirginAmerica from LAX httptcoGsB2J3c4gM'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imprime otro tweet\n",
    "print(tweets['text'][100])\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "#Aplica la funci√≥n\n",
    "remove_punct(tweets['text'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øQu√© tal el siguiente ejemplo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.686703Z",
     "iopub.status.busy": "2025-03-25T04:21:18.686429Z",
     "iopub.status.idle": "2025-03-25T04:21:18.702998Z",
     "shell.execute_reply": "2025-03-25T04:21:18.701978Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.686681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weve got quite a bit of punctuation here dont we Python DLab'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imprime un texto con contracci√≥n\n",
    "contraction_text = \"We've got quite a bit of punctuation here, don't we?!? #Python @D-Lab.\"\n",
    "\n",
    "#Aplica la funci√≥n\n",
    "remove_punct(contraction_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Advertencia: En muchos casos, queremos eliminar los signos de puntuaci√≥n despu√©s de la tokenizaci√≥n, lo cual discutiremos en breve. ¬°Esto nos indica que el orden de preprocesamiento es un asunto de importancia!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü•äDesaf√≠o 1: Preprocesamiento con m√∫ltiples pasos #\n",
    "\n",
    "Hasta ahora hemos aprendido algunas operaciones de preprocesamiento, ¬°Vamos a juntarlas en una funci√≥n! Esta funci√≥n ser√≠a muy √∫til si trabajas con datos de texto en ingl√©s desordenados y deseas preprocesarlos con una sola funci√≥n.\n",
    "\n",
    "Los datos de texto de ejemplo para el desaf√≠o 1 se muestran a continuaci√≥n. Escriba una funci√≥n para:\n",
    "\n",
    "* Poner el texto en min√∫sculas\n",
    "* Eliminar signos de puntuaci√≥n\n",
    "* Eliminar espacios en blanco adicionales\n",
    "\n",
    "¬°Si√©ntete libre de reciclar los c√≥digos que hemos usado arriba!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.704418Z",
     "iopub.status.busy": "2025-03-25T04:21:18.704121Z",
     "iopub.status.idle": "2025-03-25T04:21:18.719538Z",
     "shell.execute_reply": "2025-03-25T04:21:18.718407Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.704392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a text file that has some extra blankspace at the start and end. Blankspace is a catch-all term for spaces, tabs, newlines, and a bunch of other things that computers distinguish but to us all look like spaces, tabs and newlines.\n",
      "\n",
      "\n",
      "The Python method called \"strip\" only catches blankspace at the start and end of a string. But it won't catch it in       the middle,\t\tfor example,\n",
      "\n",
      "in this sentence.\t\tOnce again, regular expressions will\n",
      "\n",
      "help\t\tus    with this.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "challenge1_path = '/kaggle/input/maferdata/example1.txt'\n",
    "\n",
    "with open(challenge1_path, 'r') as file:\n",
    "    challenge1 = file.read()\n",
    "    \n",
    "print(challenge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.722663Z",
     "iopub.status.busy": "2025-03-25T04:21:18.722392Z",
     "iopub.status.idle": "2025-03-25T04:21:18.737570Z",
     "shell.execute_reply": "2025-03-25T04:21:18.736352Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.722640Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Paso 1: Lowercase / Min√∫sculas\n",
    "    text= text.lower()\n",
    "    \n",
    "    # Paso 2: Utilice remove_punct para eliminar signos de puntuaci√≥n\n",
    "    text = remove_punct(text)\n",
    "\n",
    "    # Paso 3: Eliminar caracteres de espacio en blanco adicionales\n",
    "    text = re.sub(pattern = blankspace_pattern, \n",
    "                    repl = blankspace_repl, \n",
    "                    string = text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.739041Z",
     "iopub.status.busy": "2025-03-25T04:21:18.738678Z",
     "iopub.status.idle": "2025-03-25T04:21:18.760603Z",
     "shell.execute_reply": "2025-03-25T04:21:18.759649Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.739009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' this is a text file that has some extra blankspace at the start and end blankspace is a catchall term for spaces tabs newlines and a bunch of other things that computers distinguish but to us all look like spaces tabs and newlines the python method called strip only catches blankspace at the start and end of a string but it wont catch it in the middle for example in this sentence once again regular expressions will help us with this '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descomente para aplicar la funci√≥n anterior al texto del desaf√≠o 1\n",
    "clean_text(challenge1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesos para tareas espec√≠ficas #\n",
    "\n",
    "Ahora que comprendemos las operaciones comunes de preprocesamiento, a√∫n quedan algunas operaciones adicionales por considerar. Nuestros datos de texto podr√≠an requerir una mayor normalizaci√≥n dependiendo del idioma, la fuente y el contenido de los datos.\n",
    "\n",
    "Por ejemplo, si trabajamos con documentos financieros, podr√≠amos querer estandarizar los s√≠mbolos monetarios convirti√©ndolos en d√≠gitos. En nuestros datos de tweets, hay numerosos hashtags y URLs. Estos se pueden reemplazar con marcadores de posici√≥n para simplificar el an√°lisis posterior.\n",
    "\n",
    "# üé¨ Demo: Eliminar Hashtags y URLs #\n",
    "\n",
    "A pesar de que las URLs, hashtags y los n√∫meros son informativos por s√≠ mismos, muchas veces no nos importa necesariamente el significado exacto de cada uno de ellos.\n",
    "\n",
    "Si bien podr√≠amos eliminarlos completamente, a menudo es informativo saber que **existe** una URL o un hashtag. En la pr√°ctica, reemplazamos las URLs y los hashtags individuales por un \"s√≠mbolo\" que preserva el hecho de que estas estructuras existen en el texto. Es com√∫n usar las cadenas \"URL\" y \"HASHTAG\" para representarlas.\n",
    "\n",
    "Dado que estos tipos de texto suelen seguir una estructura regular, son un caso adecuado para usar expresiones regulares. ¬°Vamos a aplicar estos patrones a los datos de los tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.761802Z",
     "iopub.status.busy": "2025-03-25T04:21:18.761538Z",
     "iopub.status.idle": "2025-03-25T04:21:18.778021Z",
     "shell.execute_reply": "2025-03-25T04:21:18.776965Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.761777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn\n"
     ]
    }
   ],
   "source": [
    "# Imprime el tweet de ejemplo\n",
    "url_tweet = tweets['text'][13]\n",
    "print(url_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.779188Z",
     "iopub.status.busy": "2025-03-25T04:21:18.778882Z",
     "iopub.status.idle": "2025-03-25T04:21:18.797341Z",
     "shell.execute_reply": "2025-03-25T04:21:18.796288Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.779159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel  URL \""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL \n",
    "url_pattern = r'(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])'\n",
    "url_repl = ' URL '\n",
    "re.sub(url_pattern, url_repl, url_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:21:18.798535Z",
     "iopub.status.busy": "2025-03-25T04:21:18.798281Z",
     "iopub.status.idle": "2025-03-25T04:21:18.814574Z",
     "shell.execute_reply": "2025-03-25T04:21:18.813447Z",
     "shell.execute_reply.started": "2025-03-25T04:21:18.798513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica @virginmedia I'm flying your HASHTAG  HASHTAG  skies again! U take all the HASHTAG  away from travel http://t.co/ahlXHhKiyn\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hashtag\n",
    "hashtag_pattern = r'(?:^|\\s)[ÔºÉ#]{1}(\\w+)'\n",
    "hashtag_repl = ' HASHTAG '\n",
    "re.sub(hashtag_pattern, hashtag_repl, url_tweet)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6950068,
     "sourceId": 11155604,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
