# ENTREGA FINAL PRUEBA PRCTICA

**INTEGRANTES GRUPO 9**

Jonathan Alvarez 

Juan Arias

Fernanda Pacheco

Jairo Siza


## CLASE 1: INTRODUCCIN A LAS APLICACIONES WEB, APIS, GIT, GITHUB Y CONTENEDORES. 

En un primer momento, se abord贸 el tema de la red mundial de servidores conocida como Cloud o computaci贸n en la nube, destacando que cada proveedor cuenta con funciones espec铆ficas, como es el caso de AWS, Palo Alto, Cloudflare, entre otros. Se gener贸 un debate enriquecedor acerca de las posibles formas de implementar servicios en la nube y se plante贸 la posibilidad de utilizar un modelo h铆brido, el cual combina servicios contratados en la nube con soluciones propias desarrolladas en nuestro entorno SaaS (Software as a Service).

Uno de los aspectos fundamentales de estas infraestructuras de nube es el proceso de virtualizaci贸n, el cual permite aprovechar los recursos de un mismo servidor f铆sico para crear m煤ltiples sistemas operativos de manera independiente. Existen diferentes tipos de virtualizaci贸n, cada uno con caracter铆sticas espec铆ficas. Entre ellos destacan los contenedores, que permiten una mejor distribuci贸n y aprovechamiento de recursos a nivel de sistemas operativos. Entre sus principales ventajas se encuentran la reducci贸n de costos, la alta escalabilidad y la disponibilidad confiable de los servicios. No obstante, es importante considerar ciertos riesgos, como la posible exposici贸n de datos sensibles y la alta dependencia de los proveedores de servicios en la nube.

As铆 mismo, se trabaj贸 sobre la plataforma GitHub, una herramienta de software libre que facilita el control de versiones, el seguimiento de cambios y la colaboraci贸n en proyectos de desarrollo de software y gesti贸n de archivos. Se utilizaron diversos comandos como pull, push y branch, los cuales permiten interactuar con la plataforma de manera eficiente. Es importante destacar las buenas pr谩cticas recomendadas, como evitar subir a los repositorios p煤blicos informaci贸n sensible, tales como claves API, contrase帽as, certificados o archivos de configuraci贸n .env.
Por otra parte, se revisaron conceptos clave sobre el desarrollo de aplicaciones web, diferenciando entre Frontend, que corresponde a la parte visual e interactiva con el usuario, y Backend, que corresponde a la l贸gica interna del sistema y los procesos que no son visibles para el usuario final. Se explic贸 la comunicaci贸n entre ambas partes mediante protocolos HTTP/HTTPS, haciendo uso de m茅todos como GET y PUT, y las respuestas que se pueden obtener en formatos como .csv, .xlsx o .JSON.

Adicionalmente, se profundiz贸 en las APIs REST, las cuales permiten la comunicaci贸n entre cliente y servidor a trav茅s de solicitudes HTTP/S. Se utilizaron herramientas como Postman, la cual facilita el trabajo de pruebas y gesti贸n de peticiones de manera pr谩ctica y eficiente.
Finalmente, se exploraron diversas herramientas de seguridad inform谩tica, tales como Wireshark, que permite el an谩lisis y monitoreo del tr谩fico de red y sus paquetes; Nikto, un esc谩ner de vulnerabilidades en servidores web; Burp Suite, una suite de herramientas para realizar pruebas de seguridad en aplicaciones web; y PortSwigger, una plataforma que ofrece laboratorios y cursos gratuitos enfocados en ciberseguridad, orientados a redes, aplicaciones y protecci贸n de datos.

En resumen, se abordaron conceptos fundamentales de tecnolog铆as actuales como computaci贸n en la nube, virtualizaci贸n, control de versiones, desarrollo web y ciberseguridad. Cada tema permiti贸 conocer herramientas pr谩cticas y buenas pr谩cticas aplicables en entornos reales. Este aprendizaje integral fortalece las competencias necesarias para desarrollar, gestionar y proteger infraestructuras tecnol贸gicas modernas, garantizando un mejor desempe帽o en el 谩rea de tecnolog铆a y ciberseguridad inform谩tica.


## CLASE 2: HERRAMIENTAS PARA ANLISIS DE DATOS. 

En la segunda clase se abordaron diversos temas en el 谩mbito del an谩lisis y gesti贸n de datos, dando una visi贸n sobre c贸mo extraer la informaci贸n en diferentes etapas del proceso. Uno de los temas tratados fue la miner铆a de datos, que se centra en descubrir patrones, relaciones y comportamientos ocultos dentro de grandes vol煤menes de informaci贸n. A trav茅s de t茅cnicas como la clasificaci贸n, el agrupamiento y la detecci贸n de reglas de asociaci贸n. Se utilizaron herramientas y lenguajes como Python conjuntamente con bibliotecas.

Posteriormente, se estudi贸 el tema de scraping de datos, una t茅cnica utilizada para extraer informaci贸n de p谩ginas web de forma autom谩tica. Esta habilidad es particularmente 煤til cuando los datos no est谩n disponibles en bases de datos estructuradas o en formatos descargables, se aprendi贸 a desarrollar scripts en Python empleando librer铆as como BeautifulSoup para extraer contenido HTML, as铆 como las buenas pr谩cticas para evitar sobrecargar servidores o infringir los t茅rminos de uso de los sitios.

Otro punto del curso a destacar fue el estudio de bases de datos, tanto relacionales como no relacionales. Se trabaj贸 con sistemas gestores como MySQL, PostgreSQL y SQL Server, aprendiendo a dise帽ar bases de datos eficientes mediante modelos, normalizaci贸n de datos y uso de claves primarias y for谩neas para mantener la integridad referencial. Tambi茅n se domin贸 el uso del lenguaje SQL para realizar consultas, manipulaci贸n de datos. 

Se exploraron los procesos ETL (Extract, Transform, Load), esenciales para la integraci贸n y preparaci贸n de datos provenientes de m煤ltiples fuentes. Se aprendi贸 a extraer informaci贸n desde archivos, bases de datos, transformarla aplicando limpieza, normalizaci贸n, validaci贸n y enriquecimiento, y luego cargarla en un repositorio central, como un data warehouse para el an谩lisis. Estos procesos se implementaron tanto con herramientas como Python utilizando bibliotecas como Pandas.

En conclusi贸n, la clase permiti贸 adquirir una comprensi贸n del ciclo completo del manejo de datos, desde su obtenci贸n y almacenamiento hasta su an谩lisis y transformaci贸n en informaci贸n 煤til. La combinaci贸n de miner铆a de datos, scraping, manejo de bases de datos y procesos ETL proporcion贸 un conjunto de habilidades t茅cnicas y anal铆ticas fundamentales para afrontar los retos actuales en la gesti贸n de informaci贸n, preparaci贸n de reportes, toma de decisiones y desarrollo de proyectos de ciencia de datos.


## CLASE 3: HERRAMIENTAS PARA PRESENTACIN DE DATOS.

Durante esta clase nos enfocamos en realizar un proceso completo de tratamiento de datos utilizando un archivo en formato CSV que conten铆a informaci贸n sobre correos electr贸nicos, principalmente relacionados con posibles casos de phishing. El primer paso fue importar el dataset a nuestro entorno de trabajo. Para esto, fue necesario ajustar algunos detalles como el tipo de codificaci贸n y el separador del archivo, ya que no ven铆a en el formato m谩s com煤n. Una vez que logramos cargar los datos correctamente, pudimos visualizar su estructura general y empezar a trabajar con ellos.

A continuaci贸n, llevamos a cabo un preprocesamiento de los datos. Este paso fue muy importante, ya que nos permiti贸 limpiar el dataset para asegurarnos de que fuera consistente y 煤til para el an谩lisis. Revisamos si exist铆an valores nulos, errores en los formatos, y se corrigieron algunas columnas que no estaban bien estructuradas. Tambi茅n se organizaron mejor los campos para que reflejaran claramente la informaci贸n que 铆bamos a estudiar, facilitando as铆 el an谩lisis posterior.

Una vez que los datos estuvieron limpios, pasamos a explorarlos con m谩s profundidad. Esto nos permiti贸 conocer mejor su contenido, identificar caracter铆sticas que se repet铆an y empezar a entender c贸mo se comportaban los distintos tipos de correos electr贸nicos. Gracias a esto, fue posible observar ciertos patrones que podr铆an estar relacionados con correos leg铆timos o con correos sospechosos de ser phishing.

Con esa informaci贸n, procedimos a crear visualizaciones gr谩ficas para mostrar de forma clara y visual los resultados del an谩lisis. Usamos gr谩ficos de barras, histogramas, mapas de calor, entre otros, para representar diferentes aspectos del dataset. Estas visualizaciones nos ayudaron a detectar relaciones entre las variables y a comunicar mejor nuestros hallazgos.

Finalmente, como parte del ejercicio pr谩ctico, seleccionamos los primeros registros del dataset ya procesado y los insertamos en una base de datos PostgreSQL. Esta base se encontraba dentro de un entorno de desarrollo llamado devcontainer, que nos permiti贸 simular un entorno profesional de trabajo. Esta 煤ltima parte fue clave, ya que no solo nos enfocamos en el an谩lisis, sino tambi茅n en el almacenamiento de datos, como se hace normalmente en un proyecto real.

En general, esta clase fue muy completa, ya que nos permiti贸 aplicar distintas etapas del procesamiento de datos: desde la importaci贸n y limpieza, hasta la visualizaci贸n y la integraci贸n con una base de datos. Todo esto nos ayud贸 a reforzar habilidades esenciales en el an谩lisis de datos, utilizando herramientas modernas y buenas pr谩cticas que se aplican en el mundo real.


## Colaboradores de Clase1

<a href="https://github.com/JonathanAlvarezW">
  <img src="https://avatars.githubusercontent.com/u/203370867?v=4" width="100" height="100" style="border-radius: 50%; object-fit: cover;" />
</a>
<a href="https://github.com/Pirinolas">
  <img src="https://avatars.githubusercontent.com/u/203370598?v=4" width="100" height="100" style="border-radius: 50%; object-fit: cover;" />
</a>
<a href="https://github.com/MaferPacheco">
  <img src="https://avatars.githubusercontent.com/u/203370720?v=4" width="100" height="100" style="border-radius: 50%; object-fit: cover;" />
</a>
<a href="https://github.com/JoelSiza">
  <img src="https://avatars.githubusercontent.com/u/203370601?v=4" width="100" height="100" style="border-radius: 50%; object-fit: cover;" />
</a>
